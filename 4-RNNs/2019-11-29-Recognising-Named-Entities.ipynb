{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpAJtPCNLcTw"
   },
   "source": [
    "# Recognizing Named Entites Using CoNLL Tags and GloVe Embeddings\n",
    "#### By Jonathan L. Moran (jo6155mo-s@student.lu.se)\n",
    "From the EDAN95 - Applied Machine Learning course given at Lunds Tekniska Högskola (LTH) | Ht2 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "What is covered in this post:\n",
    "*   Named entity recognition (NER)\n",
    "*   Cosine similarity \n",
    "*   Word Representation\n",
    "*   Contextual Word Representation\n",
    "*   Training a Simple RNN and Bi-directional LSTM Model\n",
    "\n",
    "Named entity recognition (abbreviated NER) is the task of _identifying_ and _categorising_ key information (called _entities_) in text. An entity is a word or string of words that have a categorical assignment. Possible entites include _Person_, _Organization_, _Time_, _Location_, etc.\n",
    "\n",
    "In this article, we will be performing two major tasks:\n",
    "1.   Recognising named entities in text.\n",
    "2.   Predicting the corresponding NER tags of a tag set.\n",
    "\n",
    "Before we dive into the code, let's first ask ourselves this–_why is this task important?_ Well, to begin with, named entity recognition is a non-trivial problem. This is because of the fact that a lot of entities, such as names or organizations, are simply made-up. In other words, we don’t have any prior knowledge of these entities. Such a dataset may not exist, or could simply be too computationally expensive to utilize. Thus, we need a model that will extract contextual information from a sentence, just like humans do.\n",
    "\n",
    "NER is suitable for any situation where a high-level overview of large text is helpful. Some practical examples of this are:\n",
    "*   Human resources– summarising applicants' CVs, parsing employee reviews/complaints.\n",
    "*   Customer support– categorising complaints and help guides, filtering by keywords.\n",
    "*   Health care– extracting important information from medical records.\n",
    "and the list goes on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Jh47rWRZbcT"
   },
   "source": [
    "## Programming\n",
    "We will be using the famous [CoNLL2003 task](http://www.cnts.ua.ac.be/conll2003/ner/) data set to perform named entity recognition. This is a well known data set consisting of many, many tagged entities. The entity categories contained the CoNLL2003 task range from locations (e.g., roads, regions, public/commercial places, abstract places) to organizations (e.g., companies, brands, political movements, named collections of people) and persons (e.g. first/middle/last names, animals, aliases). A miscellaneous category includes words/word phrases not otherwise inferred (e.g., religions, nationalities, events, media titles, etc). If you are curious, a full list of tags with associated categories can be found [here](https://blog.myassignmenttutor.com/articleblog/conll-2003-list-of-tags-with-associated-categories-of-names/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d43Gcml9RsoY"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TedmJ_z-RSWy",
    "outputId": "54317dd2-de6f-49e3-c7a5-2419c6a66f92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: regex in /opt/anaconda3/lib/python3.8/site-packages (2020.10.15)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: conlleval in /opt/anaconda3/lib/python3.8/site-packages (0.2)\r\n"
     ]
    }
   ],
   "source": [
    "# Compute the F1-score (harmonic mean of the precision and recall).\n",
    "!pip install conlleval\n",
    "import conlleval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8oL05A_Zd1Z"
   },
   "source": [
    "### Collecting a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SI0gfr_0LVlZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '../src/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vouvxLZOTi6g"
   },
   "outputs": [],
   "source": [
    "### From P. Nugues' datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets\n",
    "def load_conll2003_en():\n",
    "    \"\"\"\n",
    "    Load the CoNLL2003 datasets and split into sentences. \n",
    "    \"\"\"\n",
    "    train_file = BASE_DIR + 'NER-data/eng.train'\n",
    "    dev_file = BASE_DIR + 'NER-data/eng.valid'\n",
    "    test_file = BASE_DIR + 'NER-data/eng.test'\n",
    "    column_names = ['form', 'ppos', 'pchunk', 'ner']\n",
    "    train_sentences = open(train_file, encoding='utf8').read().strip()\n",
    "    dev_sentences = open(dev_file, encoding='utf8').read().strip()\n",
    "    test_sentences = open(test_file, encoding='utf8').read().strip()\n",
    "    return train_sentences, dev_sentences, test_sentences, column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fhBEp_uuLWHg"
   },
   "outputs": [],
   "source": [
    "### From P. Nugues' conll_dictorizer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CoNLLDictorizer, Token\n",
    "\"\"\"\n",
    "CoNLL 2009 file readers and writers for the parts of speech.\n",
    "Version with a class modeled as a vectorizer\n",
    "\"\"\"\n",
    "__author__ = \"Pierre Nugues\"\n",
    "import re\n",
    "\n",
    "class Token(dict):\n",
    "    pass\n",
    "\n",
    "\n",
    "class CoNLLDictorizer:\n",
    "\n",
    "    def __init__(self, column_names, sent_sep='\\n\\n', col_sep=' +'):\n",
    "        self.column_names = column_names\n",
    "        self.sent_sep = sent_sep\n",
    "        self.col_sep = col_sep\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, corpus):\n",
    "        corpus = corpus.strip()\n",
    "        sentences = re.split(self.sent_sep, corpus)\n",
    "        return list(map(self._split_in_words, sentences))\n",
    "\n",
    "    def fit_transform(self, corpus):\n",
    "        return self.transform(corpus)\n",
    "\n",
    "    def _split_in_words(self, sentence):\n",
    "        rows = re.split('\\n', sentence)\n",
    "        return [Token(dict(zip(self.column_names,\n",
    "                               re.split(self.col_sep, row))))\n",
    "                for row in rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkhgOOJMZt5R"
   },
   "source": [
    "#### Using the CoNLL 2003 dataset\n",
    "##### A local copy of the licensed dataset was provided in the `/usr/local/cs/EDAN95/datasets/NER-data` folder (access granted for LTH students)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 20030423 release of the data for the CoNLL-2003 shared \n",
    "task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, dev_sentences, test_sentences, column_names = load_conll2003_en()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eiUcpZ2hUGmN",
    "outputId": "b5285f9a-3a0d-411a-cdf7-e16878259a20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "hGRpYpTKUVue",
    "outputId": "7f797d71-d658-46fe-b8a4-d5be7c6238f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conll_dict = CoNLLDictorizer(column_names, col_sep=' +')\n",
    "train_dict = conll_dict.transform(train_sentences)\n",
    "dev_dict = conll_dict.transform(dev_sentences)\n",
    "test_dict = conll_dict.transform(test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first two examples in our train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "MVlM2kaEUocH",
    "outputId": "41ef1299-d643-41e8-c715-d8401fae87bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'form': '-DOCSTART-', 'ppos': '-X-', 'pchunk': 'O', 'ner': 'O'}]\n"
     ]
    }
   ],
   "source": [
    "print(train_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "uyaEcFgVVW00",
    "outputId": "79d544dd-7510-49f1-9c8b-6c1b9406476c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'form': 'EU', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'I-ORG'}, {'form': 'rejects', 'ppos': 'VBZ', 'pchunk': 'I-VP', 'ner': 'O'}, {'form': 'German', 'ppos': 'JJ', 'pchunk': 'I-NP', 'ner': 'I-MISC'}, {'form': 'call', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': 'to', 'ppos': 'TO', 'pchunk': 'I-VP', 'ner': 'O'}, {'form': 'boycott', 'ppos': 'VB', 'pchunk': 'I-VP', 'ner': 'O'}, {'form': 'British', 'ppos': 'JJ', 'pchunk': 'I-NP', 'ner': 'I-MISC'}, {'form': 'lamb', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': '.', 'ppos': '.', 'pchunk': 'O', 'ner': 'O'}]\n"
     ]
    }
   ],
   "source": [
    "print(train_dict[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the first sentence in our dev data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "3IkdI1Hg0hHa",
    "outputId": "f8e68451-b64d-4a09-b71c-9c60d2c08b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'form': 'CRICKET', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': '-', 'ppos': ':', 'pchunk': 'O', 'ner': 'O'}, {'form': 'LEICESTERSHIRE', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'I-ORG'}, {'form': 'TAKE', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': 'OVER', 'ppos': 'IN', 'pchunk': 'I-PP', 'ner': 'O'}, {'form': 'AT', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': 'TOP', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': 'AFTER', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': 'INNINGS', 'ppos': 'NNP', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': 'VICTORY', 'ppos': 'NN', 'pchunk': 'I-NP', 'ner': 'O'}, {'form': '.', 'ppos': '.', 'pchunk': 'O', 'ner': 'O'}]\n"
     ]
    }
   ],
   "source": [
    "print(dev_dict[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have successfully obtained our CoNLL2003 data, which we will used to train and validate our NER tag model. Let's move on to the next step in our pipeline–obtaining _word representations_. We will accomplish this using a set of pre-trained word vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7e0wgMxaSBR"
   },
   "source": [
    "### Collecting the Embeddings\n",
    "In this segment, we will be using a set of pre-trained word embeddings from the [GloVe](https://nlp.stanford.edu/projects/glove/) unsupervised learning algorithm for obtaining vector representations for words. But wait–_what is a word embeddding?_ Well, from the words of [Samarth Agrawal](https://towardsdatascience.com/what-the-heck-is-word-embedding-b30f67f01c81), a word embedding is a collective term used to describe models that learned to map a set of words or phrases in a vocabulary to vectors of numerical values. In short, word embeddings are the result of a very simple method to represent a word in the vector form. \n",
    "\n",
    "Word embeddings are a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Furthermore, each word is mapped to one vector and the vector values are learned in a way that resembles a neural network (thanks for that definition, [Jason Brownlee](https://machinelearningmastery.com/what-are-word-embeddings/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtRwtUvhh-eP"
   },
   "source": [
    "_1. Download the 'GloVe embeddings 6B' from https://nlp.stanford.edu/projects/glove/ and keep the `glove.6B.100d` vectors._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = '../src/glove.6B.100d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONDcsn-FiVFg"
   },
   "source": [
    "_2. LTH students: you have a local copy of this script in `usr/local/cs/EDAN95/datasets/`_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIX62mFWiRnQ"
   },
   "source": [
    "_3. Write a function that reads GloVe embeddings and store them in a dictionary, where the `keys` will be the words and the `values`, the embeddings._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, [Pierre Nugues](https://cs.lth.se/pierre/) did most of the work in this step for us. Thanks, Pierre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "jk1NMB_0aYhA"
   },
   "outputs": [],
   "source": [
    "def read_embeddings(file):\n",
    "  \"\"\"\n",
    "  Return the embeddings in the form of a dictionary (src:\n",
    "  https://github.com/pnugues/edan95/blob/master/programs/4.2-nn-pos-tagger-embeddings.ipynb)\n",
    "\n",
    "  :return: embeddings   the GloVe embeddings where `keys`=words, `values`=embeddings\n",
    "  \"\"\"\n",
    "  embeddings = {}\n",
    "  glove = open(file, encoding='utf8')\n",
    "  for line in glove:\n",
    "    values = line.strip().split()\n",
    "    word = values[0]\n",
    "    vector = np.array(values[1:], dtype='float32')\n",
    "    embeddings[word] = vector\n",
    "  glove.close()\n",
    "\n",
    "  return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = read_embeddings(embedding_file)\n",
    "embedded_words = sorted(list(embeddings_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what we got from our `read_embeddings` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xUm8M9UPaY0P",
    "outputId": "0ad28398-a5dc-4d55-809a-5de133eb2304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors\n"
     ]
    }
   ],
   "source": [
    "print('Found %s word vectors' % len(embeddings_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "om45SIEWpBt0",
    "outputId": "a8c77036-0ce3-4aed-e80c-f8a181444e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 embedding words\n"
     ]
    }
   ],
   "source": [
    "print('Found %s embedding words' % len(embedded_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, you can see that we obtained a _ton_ of embeddings from the GloVe data set. `400000` unique words, to be exact. And because these are feature vectors, we see that there are also `400000` vectors, one for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCOZxb9-jCjx"
   },
   "source": [
    "##### 4. Using a cosine similarity, compute the 5 closest words to the words _table_, _france_, and _sweden_\n",
    "In this example, we will be computing the _cosine similarity_ between each embedding. This serves as a measure of similarity between two vectors by computing the angle between them and determining whether the two vectors are pointing in roughly the same direction. We won't go into the details of this computation, since it's readily available to us using `sklearn`, but many explanations are just a click away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "ULSMSQ4bRshp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YKMpKUBheWKM"
   },
   "outputs": [],
   "source": [
    "def closest_neighbors(glove_dict):\n",
    "  #word_embedding = embeddings_idx[word]\n",
    "  neighbors = {}\n",
    "  neighbors2 = {}\n",
    "  neighbors3 = {}\n",
    "  #print(word_embedding)\n",
    "  #print(neighbors)\n",
    "  \n",
    "  for i in glove_dict:\n",
    "    val = round(cosine_similarity([glove_dict['table'], glove_dict[i]])[0][1], 4)\n",
    "    if val > 0:\n",
    "      neighbors[i] = val\n",
    "    val2 = round(cosine_similarity([glove_dict['france'], glove_dict[i]])[0][1], 4)\n",
    "    if val2 > 0:\n",
    "      neighbors2[i] = val2\n",
    "    val3 = round(cosine_similarity([glove_dict['sweden'], glove_dict[i]])[0][1], 4)\n",
    "    if val3 > 0:\n",
    "      neighbors3[i] = val3\n",
    "\n",
    "  pair_list = []\n",
    "  for k,v in sorted(neighbors.items(), key=itemgetter(1)):\n",
    "    pair_list.append(k)\n",
    "  print('Closest 5 words to \"table\": ', pair_list[-5:])\n",
    "\n",
    "  pair_list = []\n",
    "  for k,v in sorted(neighbors2.items(), key=itemgetter(1)):\n",
    "    pair_list.append(k)\n",
    "  print('Closest 5 words to \"france\": ', pair_list[-5:])\n",
    "\n",
    "  pair_list = []\n",
    "  for k,v in sorted(neighbors3.items(), key=itemgetter(1)):\n",
    "    pair_list.append(k)\n",
    "  print('Closest 5 words to \"sweden\": ', pair_list[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "pOau-UmVkKxS",
    "outputId": "a2ff15d4-8251-413a-849a-54487e83f1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest 5 words to \"table\":  ['room', 'bottom', 'place', 'tables', 'table']\n",
      "Closest 5 words to \"france\":  ['spain', 'britain', 'french', 'belgium', 'france']\n",
      "Closest 5 words to \"sweden\":  ['netherlands', 'finland', 'norway', 'denmark', 'sweden']\n"
     ]
    }
   ],
   "source": [
    "closest_neighbors(embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above described, we used cosine similarity to compute the 5 closest words to _table_, _france_ and _sweden_. The results look pretty good! The words \"bottom\" and \"table\" seem to imply a context-specific (and rather strange) co-occurence. Also, it seems odd that the \"netherlands\" is associated with the Scandinavian country \"sweden\", but nontheless–GloVe embeddings seem like a great place to start with encoding semantic understanding in our model. For the extra smart ones out there, consider improving your own NER model by fine-tuning contextual word representaions (popularised by models like BERT, ELMo, GPT-2). More on that [here](http://ai.stanford.edu/blog/contextual/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the $X$ and $Y$ Lists of Symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcT8yc_K8pjx"
   },
   "source": [
    "#### Reading the Corpus and Building Indices\n",
    "In this step we will be creating a vocabulary composed of all the words in the CoNLL and GloVe data sets. We'll use a few methods provided to us by Pierre Nugues to accomplish this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1_FXKfU8xxk"
   },
   "source": [
    "You will read the corpus with programs available from https://github.com/pnugues/edan95. These programs will enable you to load the files in the form of a list of dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n82iy-ea81n1"
   },
   "source": [
    "_1. Write a function that for each sentence returns the *x* and *y* lists of symbols consisting of words and NER tags._\n",
    "\n",
    "Some datasets you may find on the web use a different NER tagset, where `I-` is replaced with `B-`, like `B-ORG` instead of `I-ORG`. This will not change your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "smszW78y_WeY"
   },
   "outputs": [],
   "source": [
    "def build_sequences(corpus_dict, key_x='form', key_y='ner', tolower=True):\n",
    "  \"\"\"\n",
    "  Creates sequences from a list of dictionaries\n",
    "  :param corpus_dict:\n",
    "  :param key_x:\n",
    "  :param key_y:\n",
    "  :return:\n",
    "  \"\"\"\n",
    "  X = []\n",
    "  Y = []\n",
    "  \n",
    "  for sentence in corpus_dict:\n",
    "    x = []     # list of symbols containing words\n",
    "    y = []     # list of symbols containing NER tags\n",
    "    \n",
    "    for word in sentence:\n",
    "      x += [word[key_x]]\n",
    "      y += [word[key_y]]\n",
    "    if tolower:\n",
    "      x = list(map(str.lower, x))\n",
    "    X += [x]\n",
    "    Y += [y]\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQncnJul9fx5"
   },
   "source": [
    "_2. Apply this function to your datasets so you create **X** and **Y** lists of lists consisting of words and NER tags._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "b0eNEXvI_Vyy"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = build_sequences(train_dict)\n",
    "X_test, Y_test = build_sequences(test_dict)\n",
    "X_dev, Y_dev = build_sequences(dev_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkYytEHqGsGK"
   },
   "source": [
    "_For the second sentence of the training set, you should have:_\n",
    "```\n",
    "x = ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
    "y = ['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "0_lRx6V4Guc6",
    "outputId": "a94c3261-5af4-46fe-f736-e6224f8c984b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = ['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.']\n",
      "y = ['I-ORG', 'O', 'I-MISC', 'O', 'O', 'O', 'I-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print('x =', X_train[1])\n",
    "print('y =', Y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that–it matches!\n",
    "\n",
    "\n",
    "Let's also take a look at the second sentence of the dev set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "AqzzpeAC1F3_",
    "outputId": "c2357d04-0a41-448f-b8b7-1f4890a2a7ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = ['cricket', '-', 'leicestershire', 'take', 'over', 'at', 'top', 'after', 'innings', 'victory', '.']\n",
      "y = ['O', 'O', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "print('x =', X_dev[1])\n",
    "print('y =', Y_dev[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdraRLQv90Bh"
   },
   "source": [
    "_3. Create a vocabulary of all the words observed in the training set and the words in GloVe. You should find 402,595 different words._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "t1WM0jCT_Te2"
   },
   "outputs": [],
   "source": [
    "def extract_words(X_dict, Y_dict):\n",
    "  # Extracting the words in the CoNLL data set\n",
    "  vocabulary_words = sorted(list(\n",
    "      set([word for sentence in X_dict for word in sentence])))\n",
    "\n",
    "  # Extracting the NER tags in the GloVe tagset\n",
    "  ner = sorted(list(\n",
    "      set([ner for sentence in Y_dict for ner in sentence])))\n",
    "  \n",
    "  print('NER tagset: ', ner)\n",
    "\n",
    "  return vocabulary_words, ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "Rjqo_Rr0vj2i",
    "outputId": "5b46aced-a8d0-42ac-87ae-a177d88edb2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER tagset:  ['B-LOC', 'B-MISC', 'B-ORG', 'I-LOC', 'I-MISC', 'I-ORG', 'I-PER', 'O']\n"
     ]
    }
   ],
   "source": [
    "vocabulary_words, ner = extract_words(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the words in our new vocabulary. We will consider a range of 10 words that begin with the letter 'A'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "5oG75NDquubz"
   },
   "outputs": [],
   "source": [
    "def create_dict(vocabulary_words, embeddings_dict):\n",
    "  \"\"\"\n",
    "  Creates a dictionary of unique words in the CoNLL and GloVe embeddings data sets\n",
    "  Each word has a padding_length of 2, such that:\n",
    "    - index 0 is the padding symbol and,\n",
    "    - index 1 is the unknown words symbol\n",
    "\n",
    "  :param vocabulary_words:    the set of unique words in CoNLL data set\n",
    "  :param embeddings_words:    the set of unique NER tags in GloVe data set\n",
    "  :return vocabulary_words:   the set of unique words in entire vocabulary (GloVe and CoNLL)\n",
    "  :return cnt_uniq:           the number of unique words (plus padding symbols)\n",
    "  \"\"\"\n",
    "  padding_length = 2\n",
    "\n",
    "  embeddings_words = embeddings_dict.keys()\n",
    "  print('Words in GloVe:',  len(embeddings_dict.keys()))\n",
    "\n",
    "  vocabulary_words = sorted(list(set(vocabulary_words + list(embeddings_words))))\n",
    "\n",
    "  cnt_uniq = len(vocabulary_words) + padding_length\n",
    "  print('# unique words in the vocabulary: embeddings and corpus:', cnt_uniq)\n",
    "\n",
    "  return vocabulary_words, cnt_uniq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "WImkOAyTGSUg",
    "outputId": "1af50db2-a86a-47e3-f7a7-1968823db506"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in GloVe: 400000\n",
      "# unique words in the vocabulary: embeddings and corpus: 402597\n"
     ]
    }
   ],
   "source": [
    "vocabulary_words, cnt_uniq = create_dict(vocabulary_words, embeddings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this step, you should note that we have a new vocabulary consisting of CoNLL + GloVe words and NER tags. We've added 2597 words to our GloVe embeddings dictionary, leaving us with a total of 402597 unique words to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAxcVKC7-BCa"
   },
   "source": [
    "_4. Create indices and inverted indices for all the words and the NER: i.e. you will associate each word with a number. You will use index 0 for the padding symbol and 1 for unknown words._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For clarification, an _inverted index_ is an index data structure storing a mapping from content, such as words or numbers, to its location in a document or set of documents. An advantage of using an inverted index is that it allows for fast full-text searches, but comes at the cost of high storage overhead and maintence costs on update, delete and insert (more on that [here](https://www.geeksforgeeks.org/inverted-index/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "iQ2yTtc2zIbx"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fVmK61ZB_G70"
   },
   "outputs": [],
   "source": [
    "def map_idx(vocabulary_words, ner, X_dict, Y_dict):\n",
    "  \"\"\"\n",
    "  Maps the list of words (or NER tag lists) to a parallelly-sequenced index\n",
    "\n",
    "  :param vocabulary_words:   the list of lists containing CoNLL words\n",
    "  :param ner:                the list of lists containing GloVe embeddings\n",
    "  :param X_dict:             the sequenced list of dictionaries containing vocabulary words\n",
    "  :param Y_dict:             the sequenced list of dictionaries containing GloVe embeddings\n",
    "  :return X_idx:             the parallelly-sequenced indexes mapping unique words to indices\n",
    "  :return word_idx:          the padded index containing unique words in vocabulary\n",
    "  :return Y_idx:             the parallelly-sequenced indexes mapping unique tags to indices\n",
    "  :return ner_idx:           the padded index containing unique tags in vocabulary\n",
    "  \"\"\"\n",
    "  # We keep indexes 0,1 for padding and unknown word symbols\n",
    "  idx_word = dict(enumerate(vocabulary_words, start=2))\n",
    "  idx_ner = dict(enumerate(ner, start=2))\n",
    "\n",
    "  word_idx = {v: k for k, v in idx_word.items()}\n",
    "  ner_idx = {v: k for k, v in idx_ner.items()}\n",
    "\n",
    "  X_idx = []\n",
    "  for x in X_dict:\n",
    "    # We map the unknown words to one\n",
    "    x_idx = list(map(lambda x: word_idx.get(x, 1), x))\n",
    "    X_idx += [x_idx]\n",
    "  \n",
    "  Y_idx = []\n",
    "  for y in Y_dict:\n",
    "    # We map the unknown words to one\n",
    "    y_idx = list(map(lambda y: ner_idx.get(y, 1), y))\n",
    "    Y_idx += [y_idx]\n",
    "  \n",
    "  return X_idx, word_idx, Y_idx, ner_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "DdvZvMoUWb_S"
   },
   "outputs": [],
   "source": [
    "X_idx, word_idx, Y_idx, ner_idx = map_idx(vocabulary_words, ner, X_train, Y_train)\n",
    "X_dev_idx, word_dev_idx, Y_dev_idx, ner_dev_idx = map_idx(vocabulary_words, ner, X_dev, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "WdLZHip-xPMv",
    "outputId": "d44af2ab-c89a-4a3b-e2d4-3e90ce50f501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second sentences of X_idx, word indices [[935], [142143, 307143, 161836, 91321, 363368, 83766, 85852, 218260, 936], [284434, 79019], [86920, 15423]]\n",
      "Second sentences of Y_idx, NER indices [[9], [7, 9, 6, 9, 9, 9, 6, 9, 9], [8, 8], [5, 9]]\n"
     ]
    }
   ],
   "source": [
    "print('Second sentences of X_idx, word indices', X_idx[:4])\n",
    "print('Second sentences of Y_idx, NER indices', Y_idx[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "RYkwXsZz3L52",
    "outputId": "b69c5768-617f-4892-e65b-a029911d5700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second sentences of X_dev_idx, word indices [[935], [113351, 679, 221875, 354360, 275584, 63471, 364505, 49150, 192163, 381011, 936], [227217, 15431], [388337, 190955, 53074, 285387, 334414, 364408, 154113, 153033, 26724, 271939, 155673, 62067, 221875, 72732, 339658, 89620, 55656, 192163, 56102, 27037, 315734, 190291, 370791, 119532, 363368, 354360, 275584, 63471, 359698, 176975, 270183, 359698, 112003, 98068, 936]]\n",
      "Second sentences of Y_dev_idx, NER indices [[9], [9, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9], [5, 9], [6, 6, 9, 8, 8, 9, 9, 9, 9, 9, 9, 9, 7, 9, 7, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]]\n"
     ]
    }
   ],
   "source": [
    "print('Second sentences of X_dev_idx, word indices', X_dev_idx[:4])\n",
    "print('Second sentences of Y_dev_idx, NER indices', Y_dev_idx[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "te02q_RrY0jp"
   },
   "source": [
    "### Building the Embeddings Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matrix will be used to train our model on the vocabulary we constructed earlier. An embeddings matrix consists of word embeddings represented as a dense real-valued low dimensional matrix. Each row of the matrix is associated with a word in our vocabulary and each column in the matrix represents a latent feature. In our use case, we will consider the dimensionality of each embedding `N` to be of length `100`. That is, each unique word `M` in our vocabulary will have `100` features (elements) in every 1-D vertical array. According to our specification below, we will initialise these 100 elements to be random values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKKpk-Rsjwja"
   },
   "source": [
    "_1. Create a matrix of dimensions `(M, N)`, where `M` will be the size of the vocabulary (the unique words in the training set and the words in GloVe), and `N` will be the dimension of the embeddings._\n",
    "* The padding symbol and the unknown word symbol will be part of the vocabulary.\n",
    "* The shape of your matrix should be `(402597, 100)`. Initialise it with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "G_2LPx6C5Z2p"
   },
   "outputs": [],
   "source": [
    "def create_embeddings_matrix(vocabulary_words, embeddings_dict, word_idx):\n",
    "  \"\"\"\n",
    "  Create an embeddings matrix of size (M,N) where \n",
    "    M = size of vocabulary_words, and \n",
    "    N = dimension of embeddings\n",
    "\n",
    "  :param vocabulary_words:    the unique words in the training set and in GloVe\n",
    "  :param embeddings_dict:     the GloVe embeddings\n",
    "  :param word_idx:            the unique words \n",
    "  :return embedding_matrix:   the MxN matrix of M vocabulary words and N embeddings\n",
    "  \"\"\"\n",
    "  EMBEDDING_DIM = 100\n",
    "  rdstate = np.random.RandomState(1234567)\n",
    "  # random = np.random.random((len(vocabulary_words)+2, EMBEDDING_DIM))\n",
    "  embedding_matrix = rdstate.uniform(-0.05, 0.05,\n",
    "                                     (len(vocabulary_words) + 2,\n",
    "                                      EMBEDDING_DIM))\n",
    "\n",
    "  for word in vocabulary_words:\n",
    "    if word in embeddings_dict:\n",
    "      # If the words are in the embeddings, we fill them with a value\n",
    "      embedding_matrix[word_idx[word]] = embeddings_dict[word]\n",
    "\n",
    "  return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaZEdEoNjwsN"
   },
   "source": [
    "_2. Fill the matrix with the GloVe embeddings when available. You will use the indices from the previous section._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "aqKiAvgZk9fD"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = create_embeddings_matrix(vocabulary_words, embeddings_dict, word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "2abMiWOzaMnm",
    "outputId": "5d9e86a3-a132-48fc-a9d3-7fda388889d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embedding matrix: (402597, 100)\n",
      "Embedding of table [-0.61453998  0.89692998  0.56770998  0.39102    -0.22437     0.49035001\n",
      "  0.10868     0.27410999 -0.23833001 -0.52152997  0.73550999 -0.32653999\n",
      "  0.51304001  0.32415    -0.46709001  0.68050998 -0.25497001 -0.040484\n",
      " -0.54417998 -1.05480003 -0.46691999  0.23557     0.31233999 -0.34536999\n",
      "  0.14793    -0.53745002 -0.43215001 -0.48723999 -0.51019001 -0.90509999\n",
      " -0.17918999 -0.018376    0.09719    -0.31623     0.75120002  0.92236\n",
      " -0.49965     0.14036    -0.28296    -0.97443002 -0.0094408  -0.62944001\n",
      "  0.14711    -0.94375998  0.0075222   0.18565001 -0.99172002  0.072789\n",
      " -0.18474001 -0.52901     0.38995001 -0.45677    -0.21932     1.37230003\n",
      " -0.29635999 -2.2342     -0.36667001  0.04987     0.63420999  0.53275001\n",
      " -0.53955001  0.31398001 -0.44698    -0.38389     0.066668   -0.02168\n",
      "  0.20558     0.59456003 -0.24891999 -0.52794999 -0.3761      0.077104\n",
      "  0.75221997 -0.2647     -0.0587      0.67540997 -0.16559    -0.49278\n",
      " -0.26326999 -0.21214999  0.24316999  0.17005999 -0.29260001 -0.50089997\n",
      " -0.56638002 -0.40377    -0.48451999 -0.32539001  0.75292999  0.0049585\n",
      " -0.32115     0.28898999 -0.042392    0.63862997 -0.20332    -0.46785\n",
      " -0.15661     0.21789999  1.41429996  0.40033999]\n",
      "Embedding of the padding symbol, idx 0, random numbers [-0.02629708 -0.04923516 -0.04801697 -0.01869074 -0.04005453 -0.03048257\n",
      " -0.0292702  -0.03350688  0.0211879  -0.04679333 -0.03026304  0.0464557\n",
      "  0.00738946  0.01992277  0.04746414  0.01543505 -0.02391317 -0.03035904\n",
      "  0.03614633 -0.01292743 -0.01311645  0.00429138  0.01827985  0.03228761\n",
      " -0.03686076 -0.04223968  0.03409078 -0.0278994   0.02529113 -0.0156977\n",
      " -0.04902496 -0.01042922 -0.029072   -0.00319148 -0.01353996  0.00950514\n",
      "  0.0413734  -0.00028032 -0.01519774 -0.01369095  0.03702888 -0.01152137\n",
      "  0.03035301  0.00264644 -0.0463597  -0.02356203 -0.033484   -0.02621933\n",
      " -0.03773337  0.01826283  0.03646911 -0.04109766 -0.03953006  0.04822013\n",
      " -0.02821295 -0.0431476  -0.02476419  0.04927545 -0.02866612 -0.00881531\n",
      " -0.01183301  0.02965345 -0.03483367  0.0109977  -0.04514807 -0.0231921\n",
      "  0.00176915  0.00485835 -0.0040727  -0.01905112 -0.02361332 -0.03425079\n",
      "  0.04564135 -0.02310861  0.04121954 -0.04504611  0.00330172  0.01987282\n",
      " -0.00783856  0.0198199  -0.02306001 -0.0187176   0.03677814 -0.03901311\n",
      " -0.03016801  0.03832556  0.02892775  0.04970791 -0.01038987  0.04192337\n",
      "  0.0403074  -0.01217054  0.04221675 -0.02228818  0.03978376 -0.00845296\n",
      "  0.00691154  0.01943966  0.00093845 -0.03084958]\n"
     ]
    }
   ],
   "source": [
    "print('Shape of embedding matrix:', embedding_matrix.shape)\n",
    "print('Embedding of table', embedding_matrix[word_idx['table']])\n",
    "print('Embedding of the padding symbol, idx 0, random numbers', \n",
    "      embedding_matrix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have constructed our vocabulary embeddings matrix, we will begin to conduct our final step in the pre-processing stage so we can train a model to perform our desired task. In case you have forgotten by now, that is to create a NER model to locate and classify named entities in text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q5Vu44JY6dd"
   },
   "source": [
    "### Creating the **X** and **Y** Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_39oxZ5k-W-"
   },
   "source": [
    "You will now create the input and output sequences with numerical indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NzAF-Jmk-tF"
   },
   "source": [
    "_1. Convert the **X** and **Y** lists of symbols in lists of numbers using the indices you created._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7rGbUNolQjh"
   },
   "source": [
    "_2. Pad the sentences using the `pad_sequences` function. As maximum length and `maxlen` argument, you will use 150 or greater. What matters is that you have a length that is larger than the maximum length you observed in your training and development corpora._\n",
    "\n",
    "For further clarification, the `pad_sequences` function will pad each sentence with the value `0` to a specific length, in our case, that is `150`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "E69l6O2FpF5W"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "rEa5DsE1-LOV"
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LEN=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "WQN9xUucYTik"
   },
   "outputs": [],
   "source": [
    "# Padding the training set with maxlen of GloVe data set\n",
    "X = pad_sequences(X_idx, maxlen=MAX_SEQUENCE_LEN)\n",
    "Y = pad_sequences(Y_idx, maxlen=MAX_SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "MZbYfup6Yt1T",
    "outputId": "ec028c4d-21c8-4153-dbdd-7973f204624e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0 935]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 9]\n"
     ]
    }
   ],
   "source": [
    "# The first sentence of our vocabulary index, padded with maxlen of GloVe data set\n",
    "print(X[0])\n",
    "# The first sequence of embeddings, padded with maxlen of GloVe data set\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "gWT0YQRDZMb_"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `to_categorical` function returns a matrix of binary values where each row equals the length of the input vector and the number of columns corresponds to the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "oeK-ppFpZHzv",
    "outputId": "4d27c0c8-a0e1-4a6b-c72a-af9477a06ab7"
   },
   "outputs": [],
   "source": [
    "# The number of NER tags and 0 (padding symbol)\n",
    "Y_train_cat = to_categorical(Y, num_classes=len(ner) + 2)\n",
    "#print(Y_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the test set\n",
    "X_test_idx, word_test_idx, Y_test_idx, ner_test_idx = map_idx(vocabulary_words, ner, X_test, Y_test)\n",
    "\n",
    "# Padding the test set with maxlen of GloVe data set\n",
    "X_test_padded = pad_sequences(X_test_idx, maxlen=MAX_SEQUENCE_LEN)\n",
    "Y_test_padded = pad_sequences(Y_test_idx, maxlen=MAX_SEQUENCE_LEN)\n",
    "\n",
    "# 0 (padding), 1 (missing word)\n",
    "Y_test_cat = to_categorical(Y_test_padded, num_classes=len(ner) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_test set: (3684, 150)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_test set:', X_test_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_test set: (3684, 150, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Y_test set:', Y_test_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IYwvnRSlpCr"
   },
   "source": [
    "_3. Do the same for the development set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "DQrj3JsGzo3B"
   },
   "outputs": [],
   "source": [
    "# Padding the dev set with maxlen of GloVe data set\n",
    "X_dev_padded = pad_sequences(X_dev_idx, maxlen=MAX_SEQUENCE_LEN)\n",
    "Y_dev_padded = pad_sequences(Y_dev_idx, maxlen=MAX_SEQUENCE_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "DAvI54dg4nJw",
    "outputId": "45653bd7-0e24-4de8-9416-9dc0c1c1ba10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0 935]\n"
     ]
    }
   ],
   "source": [
    "# The first sentence of our dev vocabulary index, padded with maxlen of GloVe data set\n",
    "print(X_dev_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 9]\n"
     ]
    }
   ],
   "source": [
    "# The first sequence of dev embeddings, padded with maxlen of GloVe data set\n",
    "print(Y_dev_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 899
    },
    "id": "41OsFjI04x9O",
    "outputId": "454ead18-9494-4f91-9465-6b957c550773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# The number of NER tags (2 missing) and 0 (padding symbol) in our dev set\n",
    "Y_dev_cat = to_categorical(Y_dev_padded, num_classes=len(ner) + 2)\n",
    "print(Y_dev_cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_dev set: (3466, 150)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_dev set:', X_dev_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_dev set: (3466, 150, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Y_dev set:', Y_dev_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have made it this far– congratulations! We finished preparing our data. That was a lot of steps, so let's recap. We:\n",
    "1.   Collected a data set using both CoNLL2003 and GloVe embeddings data.\n",
    "2.   Constructed a vocabulary of all unique words in each.\n",
    "3.   Obtained parallely-sequenced and inverted indices.\n",
    "4.   Generated sequenced X and Y data using the keras `to_categorical()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI_ggUvyZC8u"
   },
   "source": [
    "### Building a Simple Reccurent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first be training a `keras simpleRNN` model on our data. While simple RNN models can classify the input sequence taking into account the long time dependencies, they face the problem of vanishing gradients ([Y Benigo, 1994](https://ieeexplore.ieee.org/document/279181)). To solve this problem, we will be using another RNN architecture known as the Long Short-Term Memory (LSTM). The LSTM, namely the bi-directional LSTM, is a widely-accepted architecture for performing NER. However, let's start with this simple model so we can show you some improved results in the later part of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "kAU6yBUbSHbq"
   },
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras import utils\n",
    "from keras.layers import SimpleRNN, Dense, Embedding\n",
    "from keras.models import load_model\n",
    "import math\n",
    "import bisect\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ABX8guDluyG"
   },
   "source": [
    "_1. Create a simple recurrent network and train a model with the training set. As layers, you will use `Embedding`, `SimpleRNN`, and `Dense`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "01d4TLmI5lpV"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "OPTIMIZER = 'rmsprop'\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "NB_CLASSES = len(ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaRfwPLfMs03"
   },
   "source": [
    "Relative classification accuracy is high (trainable == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "x8R40xW6CDnP",
    "outputId": "fc25018a-00bc-4f68-84df-2e3d7113f4a4"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(len(vocabulary_words) + 2,\n",
    "                           EMBEDDING_DIM,\n",
    "                           mask_zero=True))\n",
    "model.layers[0].set_weights([embedding_matrix])\n",
    "# The default is True\n",
    "model.layers[0].trainable = True\n",
    "model.add(SimpleRNN(EMBEDDING_DIM, return_sequences=True))\n",
    "model.add(Dense(units=NB_CLASSES+2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LHVXNFllvDl"
   },
   "source": [
    "_2. Compile and fit your network. You will report the training and validation losses and accuracies and comment on the possible overfit._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "id": "z_rEfHuaCEf4",
    "outputId": "4a8c64cd-a50f-41b9-a217-5ea90ec5bfb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         40259700  \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, None, 100)         20100     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 10)          1010      \n",
      "=================================================================\n",
      "Total params: 40,280,810\n",
      "Trainable params: 40,280,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 44s 365ms/step - loss: 0.0641 - acc: 0.8083 - val_loss: 0.0221 - val_acc: 0.9357\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 43s 361ms/step - loss: 0.0169 - acc: 0.9436 - val_loss: 0.0180 - val_acc: 0.9464\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 42s 351ms/step - loss: 0.0125 - acc: 0.9574 - val_loss: 0.0174 - val_acc: 0.9455\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 40s 338ms/step - loss: 0.0105 - acc: 0.9648 - val_loss: 0.0137 - val_acc: 0.9601\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 41s 345ms/step - loss: 0.0088 - acc: 0.9695 - val_loss: 0.0142 - val_acc: 0.9567\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 44s 370ms/step - loss: 0.0077 - acc: 0.9732 - val_loss: 0.0132 - val_acc: 0.9602\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 41s 345ms/step - loss: 0.0070 - acc: 0.9761 - val_loss: 0.0136 - val_acc: 0.9571\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 41s 349ms/step - loss: 0.0064 - acc: 0.9780 - val_loss: 0.0125 - val_acc: 0.9626\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 41s 350ms/step - loss: 0.0058 - acc: 0.9793 - val_loss: 0.0123 - val_acc: 0.9650\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 42s 352ms/step - loss: 0.0053 - acc: 0.9814 - val_loss: 0.0123 - val_acc: 0.9645\n"
     ]
    }
   ],
   "source": [
    "trained = True\n",
    "if trained == False:\n",
    "    history = model.fit(X, Y_train_cat, \n",
    "                        epochs=EPOCHS, \n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        validation_data=(X_dev_padded, Y_dev_cat)\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained == False:\n",
    "    model.save_weights('model1.model')\n",
    "else:\n",
    "    model.load_weights('model1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualising the training metrics\n",
    "Now that we've trained our model, we want to visualise the model's training and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'bo', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xUrL6XhmOYK"
   },
   "source": [
    "_3. Apply your network to the test set and report the accuracy you obtained. You will use the `evaluate` method._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "DtY1DAAuGD3P",
    "outputId": "3e354e68-f53b-4210-c589-378083631fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 2s 20ms/step - loss: 0.0145 - acc: 0.9503\n",
      "Test loss: 0.014512376859784126\n",
      "Test accuracy: 0.950285017490387\n"
     ]
    }
   ],
   "source": [
    "# Evaluates with the padding symbol\n",
    "test_loss, test_acc = model.evaluate(X_test_padded, Y_test_cat)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIEJo3l-Is5I"
   },
   "source": [
    "#### Evaluating your System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tfrASrcIz0U"
   },
   "source": [
    "_1. Use the predict method to predict the tags of the whole test set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "lRkQyIy0GIx1",
    "outputId": "ed1e1751-6476-4a2e-a6ee-b5d3129fd6aa"
   },
   "outputs": [],
   "source": [
    "# Evaluating on all the test corpus\n",
    "y_pred = model.predict(X_test_padded)\n",
    "y_preds = np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove padding\n",
    "Y_test_ = [y[y != 0.] for y in np.argmax(Y_test_cat, axis = 2)]\n",
    "Y_pred_ = [y_hat[y != 0.] for y, y_hat in zip(np.argmax(Y_test_cat, axis = 2), y_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [9 9 5 9 9 9 9 5 9 9 9 9]\n",
      "Actual   : [9 9 5 9 9 9 9 8 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# Compare first predicted sentence tags to actual\n",
    "print(\"Predicted:\", Y_pred_[1])\n",
    "print(\"Actual   :\", Y_test_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7z3ruh0I5Dp"
   },
   "source": [
    "_2. Write your results in a file, where the two last columns will be the hand-annotated tag and the predicted tag. The fields must be separated by a space and each line must end with a new line: `\\n`._\n",
    "\n",
    "Written by Jonas Lundgren, link [here](https://github.com/LurreMcFly/edan95/blob/master/Lab4/lab4.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(file, corpus_dict, ner, y, y_pred):\n",
    "    \n",
    "    with open(file, 'w', encoding='utf8') as f_out:\n",
    "        for i, sentence in enumerate(corpus_dict):\n",
    "            sentence_lst = []\n",
    "            for j, row in enumerate(sentence):\n",
    "                items = str(row.get('form')) + ' ' + str(ner[y[i][j]- 2]) + ' ' + str(ner[y_pred[i][j] - 2])\n",
    "                sentence_lst += items + '\\n'\n",
    "            sentence_lst += '\\n'\n",
    "            f_out.write(''.join(sentence_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing results to file\n",
    "save(\"output1.txt\", test_dict, ner, Y_test_, Y_pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Apply conlleval to your output. Report the F1 result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7279680166869459\n"
     ]
    }
   ],
   "source": [
    "lines = open(\"output1.txt\", encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "improved_score = res['overall']['chunks']['evals']['f1']\n",
    "print(\"F1 score:\", improved_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOLHN4T5KOPw"
   },
   "source": [
    "#### Building a LSTM Network\n",
    "While the above model produces pretty good results, we want to consider using a Long Short-Term Memory (LSTM) model to address the problem of vanishing gradients. The type of LSTM we will be using is called a `Bidirectional` layer because information from its inputs will be preserved from both directions, _past to future_ and _future to past_. The use of the two hidden states combined results in better performance by allowing the model to learn both past and future contexts of a word.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bkq1GuWpKSh5"
   },
   "source": [
    "_1. Create a simple LSTM network and train a model with the train set. As layers, you will use `Embedding`, `LSTM`, and `Dense`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "XUjhQxmEMcrq"
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "Il3Q02rlKRH7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 150, 100)          40259700  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 150, 200)          160800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150, 10)           2010      \n",
      "=================================================================\n",
      "Total params: 40,422,510\n",
      "Trainable params: 40,422,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Embedding(len(vocabulary_words) + 2,\n",
    "                           EMBEDDING_DIM,\n",
    "                           mask_zero=True,\n",
    "                           input_length=MAX_SEQUENCE_LEN))\n",
    "# model.add(SimpleRNN(100, return_sequences=True))\n",
    "# model.add(Bidirectional(SimpleRNN(100, return_sequences=True)))\n",
    "model2.add(Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True)))\n",
    "model2.add(Dense(units=NB_CLASSES+2, activation='softmax'))\n",
    "\n",
    "model2.layers[0].set_weights([embedding_matrix])\n",
    "# The default is True\n",
    "model2.layers[0].trainable = True\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2. Compile and fit your network. You will report the training and validation losses and accuracies and comment on the possible overfit._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "hx84j_CKKraL",
    "outputId": "236ce65f-9f1b-464d-aff8-bad5e8dc659f"
   },
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 107s 836ms/step - loss: 0.0555 - acc: 0.8288 - val_loss: 0.0204 - val_acc: 0.9388\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 101s 854ms/step - loss: 0.0155 - acc: 0.9504 - val_loss: 0.0134 - val_acc: 0.9608\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 112s 951ms/step - loss: 0.0102 - acc: 0.9658 - val_loss: 0.0123 - val_acc: 0.9629\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 141s 1s/step - loss: 0.0083 - acc: 0.9723 - val_loss: 0.0106 - val_acc: 0.9675\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 141s 1s/step - loss: 0.0066 - acc: 0.9782 - val_loss: 0.0109 - val_acc: 0.9675\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 132s 1s/step - loss: 0.0056 - acc: 0.9820 - val_loss: 0.0100 - val_acc: 0.9712\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 138s 1s/step - loss: 0.0043 - acc: 0.9855 - val_loss: 0.0097 - val_acc: 0.9708\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 125s 1s/step - loss: 0.0039 - acc: 0.9869 - val_loss: 0.0089 - val_acc: 0.9750\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 124s 1s/step - loss: 0.0031 - acc: 0.9895 - val_loss: 0.0089 - val_acc: 0.9729\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 134s 1s/step - loss: 0.0026 - acc: 0.9920 - val_loss: 0.0099 - val_acc: 0.9740\n"
     ]
    }
   ],
   "source": [
    "trained = False\n",
    "if trained == False:\n",
    "    history = model2.fit(X, Y_train_cat, \n",
    "                         epochs=EPOCHS, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         validation_data=(X_dev_padded, Y_dev_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained == False:\n",
    "    model2.save_weights('model2.model')\n",
    "else:\n",
    "    model2.load_weights('model2.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualising the training metrics\n",
    "Now that we've trained our model, we want to visualise the model's training and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgiElEQVR4nO3de5gU9Z3v8feHi+KACipRwyiDWRJEkYsTVLyRDdnF4NFo9AmEKIguIcbLms3F6EnwJMvGE914eWLWJYnG6CTEuOoxLomJJB6za050VFC5GUTQ8ZaRREBAAf2eP6pmaJq59GDPdE3N5/U880xX1a+qv1098+nqX/26WhGBmZnlV69KF2BmZp3LQW9mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoO+BJP1S0oxyt60kSWskTeqE7Yakv0lv3yzpa6W03Y37mS7p17tbp1lb5HH03YOkNwsmq4C3gXfS6c9GRF3XV5UdktYAF0TEg2XebgDDI2JVudpKqgGeB/pGxPayFGrWhj6VLsBKExEDmm63FWqS+jg8LCv895gN7rrp5iRNlNQg6SuSXgVulTRI0v2SGiX9Nb1dXbDOQ5IuSG/PlPRfkq5N2z4v6ZTdbDtM0sOSNkp6UNJNku5ope5SavympP9Ot/drSQcULD9H0lpJ6yRd2cb+OVbSq5J6F8w7Q9JT6e3xkv4g6Q1Jr0j6rqQ9WtnWjyT9c8H0l9J1XpY0q6jtFElPStog6UVJVxUsfjj9/YakNyUd17RvC9afIOkxSevT3xNK3Tcd3M/7Sbo1fQx/lXRvwbLTJS1OH8Nzkian83fqJpN0VdPzLKkm7cI6X9ILwG/T+T9Pn4f16d/IEQXr7yXpX9Pnc336N7aXpP+UdHHR43lK0idaeqzWOgd9PhwE7AcMBWaTPK+3ptOHAluA77ax/jHASuAA4NvADyVpN9r+BHgU2B+4CjinjfsspcZPA+cB7wP2AL4IIGkk8G/p9t+f3l81LYiI/wdsAv62aLs/SW+/A1yWPp7jgI8CF7ZRN2kNk9N6PgYMB4rPD2wCzgUGAlOAzxUE1Enp74ERMSAi/lC07f2A/wRuTB/bd4D/lLR/0WPYZd+0oL39fDtJV+AR6bauS2sYD/wY+FL6GE4C1rRyHy05GTgc+Pt0+pck++l9wBNAYVfjtcDRwASSv+MvA+8CtwGfaWokaTQwBFjYgToMICL8081+SP7hJqW3JwJbgX5ttB8D/LVg+iGSrh+AmcCqgmVVQAAHdaQtSYhsB6oKlt8B3FHiY2qpxv9ZMH0h8Kv09teBBQXL+qf7YFIr2/5n4Jb09t4kITy0lbb/CNxTMB3A36S3fwT8c3r7FuDqgnYfLGzbwnavB65Lb9ekbfsULJ8J/Fd6+xzg0aL1/wDMbG/fdGQ/AweTBOqgFtr9e1O9bf39pdNXNT3PBY/tsDZqGJi22ZfkhWgLMLqFdnsCfyE57wHJC8L3OuN/Ku8/PqLPh8aIeKtpQlKVpH9P3wpvIOkqGFjYfVHk1aYbEbE5vTmgg23fD/ylYB7Ai60VXGKNrxbc3lxQ0/sLtx0Rm4B1rd0XydH7mZL2BM4EnoiItWkdH0y7M15N6/gXkqP79uxUA7C26PEdI+l3aZfJemBOidtt2vbaonlrSY5mm7S2b3bSzn4+hOQ5+2sLqx4CPFdivS1p3jeSeku6Ou3+2cCOdwYHpD/9WrqviHgbuBP4jKRewDSSdyDWQQ76fCgeOvVPwIeAYyJiH3Z0FbTWHVMOrwD7SaoqmHdIG+3fS42vFG47vc/9W2scEctIgvIUdu62gaQLaAXJUeM+wBW7UwPJO5pCPwHuAw6JiH2Bmwu2295Qt5dJuloKHQq8VEJdxdrazy+SPGcDW1jvReADrWxzE8m7uSYHtdCm8DF+GjidpHtrX5Kj/qYaXgfeauO+bgOmk3SpbY6ibi4rjYM+n/YmeTv8RtrfO7ez7zA9Qq4HrpK0h6TjgP/RSTXeBZwq6YT0xOk3aP9v+SfAJSRB9/OiOjYAb0oaAXyuxBruBGZKGpm+0BTXvzfJ0fJbaX/3pwuWNZJ0mRzWyrYXAh+U9GlJfSR9ChgJ3F9ibcV1tLifI+IVkr7z76UnbftKanoh+CFwnqSPSuolaUi6fwAWA1PT9rXAWSXU8DbJu64qkndNTTW8S9IN9h1J70+P/o9L332RBvu7wL/io/nd5qDPp+uBvUiOlv4f8Ksuut/pJCc015H0i/+M5B+8JdezmzVGxFLg8yTh/QrwV6ChndV+SnI+47cR8XrB/C+ShPBG4PtpzaXU8Mv0MfwWWJX+LnQh8A1JG0nOKdxZsO5mYB7w30pG+xxbtO11wKkkR+PrSE5OnlpUd6mup+39fA6wjeRdzZ9JzlEQEY+SnOy9DlgP/F92vMv4GskR+F+B/8XO75Ba8mOSd1QvAcvSOgp9EXgaeIykT/5/s3M2/RgYRXLOx3aDPzBlnUbSz4AVEdHp7ygsvySdC8yOiBMqXUt35SN6KxtJH5b0gfSt/mSSftl7K1yWdWNpt9iFwPxK19KdOeitnA4iGfr3JskY8M9FxJMVrci6LUl/T3I+4zXa7x6yNrjrxsws53xEb2aWc5m8qNkBBxwQNTU1lS7DzKzbePzxx1+PiMEtLctk0NfU1FBfX1/pMszMug1JxZ+mbuauGzOznHPQm5nlnIPezCznMtlH35Jt27bR0NDAW2+91X5j63L9+vWjurqavn37VroUMyvSbYK+oaGBvffem5qaGlr/TgyrhIhg3bp1NDQ0MGzYsEqXY2ZFuk3XzVtvvcX+++/vkM8gSey///5+t2W2m+rqoKYGevVKftfVtbdGx3SbI3rAIZ9hfm7Mdk9dHcyeDZvTr+xZuzaZBpg+vTz30W2O6M3M8ujKK3eEfJPNm5P55eKgL8G6desYM2YMY8aM4aCDDmLIkCHN01u3bm1z3fr6ei655JJ272PChAnlKtfMupEXXujY/N2R26AvZ5/X/vvvz+LFi1m8eDFz5szhsssua57eY4892L59e6vr1tbWcuONN7Z7H4888sjuF2hmu6Wz+8ZLcWjxl1C2M3935DLom/q81q6FiB19XuV8EmfOnMkXvvAFPvKRj/CVr3yFRx99lAkTJjB27FgmTJjAypUrAXjooYc49dRTAbjqqquYNWsWEydO5LDDDtvpBWDAgAHN7SdOnMhZZ53FiBEjmD59Ok1XGF24cCEjRozghBNO4JJLLmnebqE1a9Zw4oknMm7cOMaNG7fTC8i3v/1tRo0axejRo7n88ssBWLVqFZMmTWL06NGMGzeO5557L98HbdZ9dEVOlGLePKiq2nleVVUyv2wiInM/Rx99dBRbtmzZLvNaM3RoRPLU7fwzdGjJm2jV3Llz45prrokZM2bElClTYvv27RERsX79+ti2bVtERPzmN7+JM888MyIifve738WUKVOa1z3uuOPirbfeisbGxthvv/1i69atERHRv3//5vb77LNPvPjii/HOO+/EscceG7///e9jy5YtUV1dHatXr46IiKlTpzZvt9CmTZtiy5YtERHx7LPPRtO+XLhwYRx33HGxadOmiIhYt25dRESMHz8+7r777oiI2LJlS/Py3dGR58is0jozJzrqjjuS+5WS33fc0fFtAPXRSqZ2q1E3peqKPi+As88+m969ewOwfv16ZsyYwZ/+9CcksW3bthbXmTJlCnvuuSd77rkn73vf+3jttdeorq7eqc348eOb540ZM4Y1a9YwYMAADjvssOZx6tOmTWP+/F2/dGfbtm1cdNFFLF68mN69e/Pss88C8OCDD3LeeedRlR467LfffmzcuJGXXnqJM844A0g+9GTWU3RVTpRi+vTyjbBpSS67brqizwugf//+zbe/9rWv8ZGPfIRnnnmGX/ziF62OKd9zzz2bb/fu3bvF/v2W2kSJXxBz3XXXceCBB7JkyRLq6+ubTxZHxC5DIEvdpllnqHT/eFflRBbkMui7pM+ryPr16xkyZAgAP/rRj8q+/REjRrB69WrWrFkDwM9+9rNW6zj44IPp1asXt99+O++88w4Af/d3f8ctt9zC5nQc11/+8hf22WcfqquruffeewF4++23m5ebdaYs9I9XIicqJZdBP306zJ8PQ4eClPyeP79z3xp9+ctf5qtf/SrHH398c7iW01577cX3vvc9Jk+ezAknnMCBBx7Ivvvuu0u7Cy+8kNtuu41jjz2WZ599tvldx+TJkznttNOora1lzJgxXHvttQDcfvvt3HjjjRx11FFMmDCBV199tey1mxXrirHj7alETlRKJr8ztra2Noq/eGT58uUcfvjhFaooG958800GDBhARPD5z3+e4cOHc9lll1W6rGZ+jqxUvXolR/LFJHj33a6vJw8kPR4RtS0ty+URfV59//vfZ8yYMRxxxBGsX7+ez372s5UuyWy39KT+8Sxw0HcjTR/UWrZsGXV1dc0jaMw6otInQaFn9Y9ngYPerAfJwklQ6Fn941ngoDfrQbJwErTJ9OmwZk3SJ79mjUO+MznozXqQLH1IyLqOg96sB/FJ0J7JQV+iiRMn8sADD+w07/rrr+fCCy9sc52mYaIf//jHeeONN3Zpc9VVVzWPaW/Nvffey7Jly5qnv/71r/Pggw92oHqzhE+C9ky5DfpyjyyYNm0aCxYs2GneggULmDZtWknrL1y4kIEDB+7WfRcH/Te+8Q0mTZq0W9uyysnCaBefBO2Zchn0nTGy4KyzzuL+++/n7bffBpLLAb/88succMIJfO5zn6O2tpYjjjiCuXPntrh+TU0Nr7/+OgDz5s3jQx/6EJMmTWq+nDEk4+Q//OEPM3r0aD75yU+yefNmHnnkEe677z6+9KUvMWbMGJ577jlmzpzJXXfdBcCiRYsYO3Yso0aNYtasWc311dTUMHfuXMaNG8eoUaNYsWLFLjX5ksZdJyujXcAnQXuk1i5rWcmfrF6m+OMf/3jce++9ERHxrW99K774xS9GxI5L/m7fvj1OPvnkWLJkSUREnHzyyfHYY4+lNQ2NxsbGqK+vjyOPPDI2bdoU69evjw984ANxzTXXRETE66+/3nxfV155Zdx4440RETFjxoz4+c9/3rysabrp0sUrV66MiIhzzjknrrvuuub7a1r/pptuivPPP3+Xx1PuSxr7MsWty9IlcS2faOMyxbk8ou+skQWF3TeF3TZ33nkn48aNY+zYsSxdunSnbpZiv//97znjjDOoqqpin3324bTTTmte9swzz3DiiScyatQo6urqWLp0aZv1rFy5kmHDhvHBD34QgBkzZvDwww83Lz/zzDMBOProo5svhlZo27Zt/MM//AOjRo3i7LPPbq671Esa+wNbpfNoF6ukkoJe0mRJKyWtknR5C8sHSbpH0lOSHpV0ZMGyyyQtlfSMpJ9K6vSLnnfWyIJPfOITLFq0iCeeeIItW7Ywbtw4nn/+ea699loWLVrEU089xZQpU1q9RHGT4ssFN5k5cybf/e53efrpp5k7d26724l2rlPUdLnj1i6H7Esadx2PdrFKajfoJfUGbgJOAUYC0ySNLGp2BbA4Io4CzgVuSNcdAlwC1EbEkUBvYGr5ym9ZZ40sGDBgABMnTmTWrFnNR/MbNmygf//+7Lvvvrz22mv88pe/bHMbJ510Evfccw9btmxh48aN/OIXv2hetnHjRg4++GC2bdtGXUHn7d57783GjRt32daIESNYs2YNq1atApIrUZ588sklPx5f0rjreLSLVVIpR/TjgVURsToitgILgNOL2owEFgFExAqgRtKB6bI+wF6S+gBVwMtlqbwNnTmyYNq0aSxZsoSpU5PXq9GjRzN27FiOOOIIZs2axfHHH9/m+uPGjeNTn/oUY8aM4ZOf/CQnnnhi87JvfvObHHPMMXzsYx9jxIgRzfOnTp3KNddcw9ixY3c6AdqvXz9uvfVWzj77bEaNGkWvXr2YM2dOyY/FlzTuOh7tYpXU7mWKJZ0FTI6IC9Lpc4BjIuKigjb/AvSLiC9IGg88krZ5XNKlwDxgC/DriGj3T9uXKe6esvoc1dUlH/F/4YWkq2TePAes5c97vUxxSx3Kxa8OVwODJC0GLgaeBLZLGkRy9D8MeD/QX9JnWilytqR6SfWNjY0llGXWviwNazSrlFKCvgE4pGC6mqLul4jYEBHnRcQYkj76wcDzwCTg+YhojIhtwN3AhJbuJCLmR0RtRNQOHjy444/ErAVZuoiXWaWUEvSPAcMlDZO0B8nJ1PsKG0gamC4DuAB4OCI2AC8Ax0qqUjKM46PA8t0t1iM/siurz42HNZqVEPQRsR24CHiAJKTvjIilkuZIajrzdziwVNIKktE5l6br/hG4C3gCeDq9v/m7U2i/fv1Yt25dZgOlJ4sI1q1bR79+nT5ytsM8rNGsG31n7LZt22hoaGh3bLlVRr9+/aiurqZv376VLmUnTX30hd03VVUe8WL509bJ2D5dXczu6tu3L8OGDat0GdbNNIW5R91YT9Ztgt5sd02f7mC3ni2X17oxs+zLwmWbewoHvZl1OX++YWed/aLnoLdO4yM2a40/37BDV7zodZtRN9a9eLSLtaVXryTUiknJF6L0JDU1SbgXGzo0+WKYUr3XSyCYdZiP2KwtWfl8QxbedXbFh/oc9NYp/IlUa0sWLtuclfMEXfGi56C3TpGVIzbLpixctjkr7zq74kXPQW+dIgtHbFmThW6CLKn0l5Rn5V1nV7zoOeitU2ThiC1LstJN0FSLX3Cy9a6zs1/0POrGrAuUa2TFe+XRUDvkbV941I1ZhWWlmyAr/dJZ0JPedfpaN2Zd4NBDWz6i7+pugqy84GRFT7kOko/ozbpAVk5OZ6lf2rqOg96sC2SlmyArLzjWtRz0lntZGWVS6eGETTVk4QXHupaDPoeyEmxZqCNLwxqzIgsvONa1PLwyZ7IyZCwrdWRlWKNZZ2treKWDPmeyEmxZqcNXSbSewuPoe5CsDJ/LSh0eZWLmoM+drARbVurwKBMzB33uZCXYslKHR5mYOehzJyvBlpU6mmrxKBPryXwy1swsB3wy1sysB3PQ51AWPqhkZtnhq1fmTPEHlZo+CQrumzbrqXxEnzO+3riZFXPQ50xWPqhkZtnhoC+zSvePZ+WDSmaWHSUFvaTJklZKWiXp8haWD5J0j6SnJD0q6ciCZQMl3SVphaTlko4r5wPIkixcKTErH1Qys+xoN+gl9QZuAk4BRgLTJI0sanYFsDgijgLOBW4oWHYD8KuIGAGMBpaXo/AsykL/eJY+qGRm2VDKqJvxwKqIWA0gaQFwOrCsoM1I4FsAEbFCUo2kA4EtwEnAzHTZVmBr2arPmKz0j/eU78E0s9KU0nUzBHixYLohnVdoCXAmgKTxwFCgGjgMaARulfSkpB9I6v+eq84o94+bWRaVEvRqYV7xdROuBgZJWgxcDDwJbCd5xzAO+LeIGAtsAnbp4weQNFtSvaT6xsbGEsvPFvePm1kWlRL0DcAhBdPVwMuFDSJiQ0ScFxFjSProBwPPp+s2RMQf06Z3kQT/LiJifkTURkTt4MGDO/YoMsL942aWRaX00T8GDJc0DHgJmAp8urCBpIHA5rQP/gLg4YjYAGyQ9KKkD0XESuCj7Ny3nzvuHzezrGk36CNiu6SLgAeA3sAtEbFU0px0+c3A4cCPJb1DEuTnF2ziYqBO0h7AauC8Mj8GMzNrgy9TbGaWA75MsZlZD+agL7NKXwLBzKyYL1NcRr5EsJllkY/oyygLl0AwMyvmoC+jrFwCwcyskIO+jHwJBDPLIgd9GfkSCGaWRQ76MvIlEMwsizzqpsx8CQQzyxof0ZuZ5ZyD3sws5xz0ZmY556A3M8s5B72ZWc456M3Mcs5Bb2aWcw56M7Occ9CbmeWcg97MLOcc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoDczyzkHvZlZzjnozcxyrqSglzRZ0kpJqyRd3sLyQZLukfSUpEclHVm0vLekJyXdX67CzcysNO0GvaTewE3AKcBIYJqkkUXNrgAWR8RRwLnADUXLLwWWv/dyzcyso0o5oh8PrIqI1RGxFVgAnF7UZiSwCCAiVgA1kg4EkFQNTAF+ULaqzcysZKUE/RDgxYLphnReoSXAmQCSxgNDgep02fXAl4F330uh7amrg5oa6NUr+V1X15n3ZmbWfZQS9GphXhRNXw0MkrQYuBh4Etgu6VTgzxHxeLt3Is2WVC+pvrGxsYSydqirg9mzYe1aiEh+z57tsDczg9KCvgE4pGC6Gni5sEFEbIiI8yJiDEkf/WDgeeB44DRJa0i6fP5W0h0t3UlEzI+I2oioHTx4cIcexJVXwubNO8/bvDmZb2bW05US9I8BwyUNk7QHMBW4r7CBpIHpMoALgIfT8P9qRFRHRE263m8j4jNlrB+AF17o2Hwzs56k3aCPiO3ARcADJCNn7oyIpZLmSJqTNjscWCppBcnonEs7q+CWHHpox+abmfUkfUppFBELgYVF824uuP0HYHg723gIeKjDFZZg3rykT76w+6aqKplvZtbT5eKTsdOnw/z5MHQoSMnv+fOT+WZmPV1JR/TdwfTpDnYzs5bk4ojezMxa56A3M8s5B72ZWc456M3Mcs5Bb2aWcw56M7Occ9CbmeWcg97MLOcc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoDczyzkHvZlZzjnozcxyzkFvZpZzDnozs5xz0JuZ5ZyD3sws5xz0ZmY556A3M8s5B72ZWc456M3Mcs5Bb2aWcyUFvaTJklZKWiXp8haWD5J0j6SnJD0q6ch0/iGSfidpuaSlki4t9wMwM7O2tRv0knoDNwGnACOBaZJGFjW7AlgcEUcB5wI3pPO3A/8UEYcDxwKfb2FdMzPrRKUc0Y8HVkXE6ojYCiwATi9qMxJYBBARK4AaSQdGxCsR8UQ6fyOwHBhSturNzKxdpQT9EODFgukGdg3rJcCZAJLGA0OB6sIGkmqAscAfd7NWMzPbDaUEvVqYF0XTVwODJC0GLgaeJOm2STYgDQD+A/jHiNjQ4p1IsyXVS6pvbGwspXYzMytBnxLaNACHFExXAy8XNkjD+zwASQKeT3+Q1Jck5Osi4u7W7iQi5gPzAWpra4tfSMzMbDeVckT/GDBc0jBJewBTgfsKG0gamC4DuAB4OCI2pKH/Q2B5RHynnIWbmVlp2j2ij4jtki4CHgB6A7dExFJJc9LlNwOHAz+W9A6wDDg/Xf144Bzg6bRbB+CKiFhY3odhZmatKaXrhjSYFxbNu7ng9h+A4S2s91+03MdvZmZdxJ+MNTPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCznHPRmZjnnoDczyzkHvZlZzjnozcxyzkFvZpZzDnozs5xz0JuZ5ZyD3sws5xz0ZmY556A3M8s5B72ZWc456M3Mcs5Bb2aWcw56M7Occ9CbmeWcg97MLOcc9GZmOeegNzPLOQe9mVnOOejNzHLOQW9mlnMOejOznHPQm5nlnIPezCznSgp6SZMlrZS0StLlLSwfJOkeSU9JelTSkaWua2ZmnavdoJfUG7gJOAUYCUyTNLKo2RXA4og4CjgXuKED65qZWScq5Yh+PLAqIlZHxFZgAXB6UZuRwCKAiFgB1Eg6sMR1zcysE5US9EOAFwumG9J5hZYAZwJIGg8MBapLXNfMzDpRKUGvFuZF0fTVwCBJi4GLgSeB7SWum9yJNFtSvaT6xsbGEsoyM7NS9CmhTQNwSMF0NfByYYOI2ACcByBJwPPpT1V76xZsYz4wH6C2trbFFwMzM+u4Uo7oHwOGSxomaQ9gKnBfYQNJA9NlABcAD6fh3+66ZmbWudo9oo+I7ZIuAh4AegO3RMRSSXPS5TcDhwM/lvQOsAw4v611O+ehmJlZSxSRvV6S2traqK+vr3QZZmbdhqTHI6K2pWX+ZKyZWc456M3Mcs5Bb2aWcw56M7Occ9CbmeWcg97MLOdyE/R1dVBTA716Jb/r6ipdkZlZNpRyCYTMq6uD2bNh8+Zkeu3aZBpg+vTK1WVmlgW5OKK/8sodId9k8+ZkvplZT5eLoH/hhY7NNzPrSXIR9Ice2rH5ZmY9SS6Cft48qKraeV5VVTLfzKyny0XQT58O8+fD0KEgJb/nz/eJWDMzyMmoG0hC3cFuZrarXBzRm5lZ6xz0ZmY556A3M8s5B72ZWc456M3Mci6T3xkrqRFYW+k63qMDgNcrXURGeF/szPtjZ94fO7yXfTE0Iga3tCCTQZ8Hkupb+6Lensb7YmfeHzvz/tihs/aFu27MzHLOQW9mlnMO+s4zv9IFZIj3xc68P3bm/bFDp+wL99GbmeWcj+jNzHLOQW9mlnMO+jKSdIik30laLmmppEsrXVOlSeot6UlJ91e6lkqTNFDSXZJWpH8jx1W6pkqSdFn6f/KMpJ9K6lfpmrqSpFsk/VnSMwXz9pP0G0l/Sn8PKsd9OejLazvwTxFxOHAs8HlJIytcU6VdCiyvdBEZcQPwq4gYAYymB+8XSUOAS4DaiDgS6A1MrWxVXe5HwOSieZcDiyJiOLAonX7PHPRlFBGvRMQT6e2NJP/IQypbVeVIqgamAD+odC2VJmkf4CTghwARsTUi3qhoUZXXB9hLUh+gCni5wvV0qYh4GPhL0ezTgdvS27cBnyjHfTnoO4mkGmAs8McKl1JJ1wNfBt6tcB1ZcBjQCNyadmX9QFL/ShdVKRHxEnAt8ALwCrA+In5d2aoy4cCIeAWSA0fgfeXYqIO+E0gaAPwH8I8RsaHS9VSCpFOBP0fE45WuJSP6AOOAf4uIscAmyvS2vDtK+55PB4YB7wf6S/pMZavKLwd9mUnqSxLydRFxd6XrqaDjgdMkrQEWAH8r6Y7KllRRDUBDRDS9w7uLJPh7qknA8xHRGBHbgLuBCRWuKQtek3QwQPr7z+XYqIO+jCSJpA92eUR8p9L1VFJEfDUiqiOihuQk228joscesUXEq8CLkj6UzvoosKyCJVXaC8CxkqrS/5uP0oNPThe4D5iR3p4B/J9ybDQ3Xw6eEccD5wBPS1qczrsiIhZWriTLkIuBOkl7AKuB8ypcT8VExB8l3QU8QTJa7Ul62KUQJP0UmAgcIKkBmAtcDdwp6XySF8Ozy3JfvgSCmVm+uevGzCznHPRmZjnnoDczyzkHvZlZzjnozcxyzkFvZpZzDnozs5z7/02XFd4vCZhfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'bo', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3. Apply your network to the test set and report the accuracy you obtained. You will use the `evaluate` method._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "4BRjVROWLIsG",
    "outputId": "3e968b36-db34-41b5-994d-828a7bc24e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 9s 78ms/step - loss: 0.0128 - acc: 0.9614\n",
      "Test loss: 0.012847092002630234\n",
      "Test accuracy: 0.9614280462265015\n"
     ]
    }
   ],
   "source": [
    "# Evaluates with the padding symbol\n",
    "test_loss, test_acc = model2.evaluate(X_test_padded, Y_test_cat)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-q-YZMRwdKM"
   },
   "source": [
    "#### Evaluating your System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_UPdosAw6bT"
   },
   "source": [
    "_1. Use the predict method to predict the tags of the whole test set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539
    },
    "id": "ZJFqtjdOLtB3",
    "outputId": "5ef3667c-8cda-4e1f-ec97-d553f175470e"
   },
   "outputs": [],
   "source": [
    "y_pred = model2.predict(X_test_padded)\n",
    "y_preds = np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove padding\n",
    "Y_test_ = [y[y != 0.] for y in np.argmax(Y_test_cat, axis = 2)]\n",
    "Y_pred_ = [y_hat[y != 0.] for y, y_hat in zip(np.argmax(Y_test_cat, axis = 2), y_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [9 9 5 9 9 9 9 5 9 9 9 9]\n",
      "Actual   : [9 9 5 9 9 9 9 8 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# Compare first predicted sentence tags to actual\n",
    "print(\"Predicted:\", Y_pred_[1])\n",
    "print(\"Actual   :\", Y_test_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2. Write your results in a file, where the two last columns will be the hand-annotated tag and the predicted tag. The fields must be separated by a space and each line must end with a new line: `\\n`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing results to file\n",
    "save(\"output2.txt\", test_dict, ner, Y_test_, Y_pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3. Apply conlleval to your output. Report the F1 result._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8097796883396023\n"
     ]
    }
   ],
   "source": [
    "lines = open(\"output2.txt\", encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "improved_score = res['overall']['chunks']['evals']['f1']\n",
    "print(\"F1 score:\", improved_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we were able to impove the test accuracy of our initial model 8.2% by adding a Bidirectional LSTM layer. No complaints there. But what if I told you we could go further with our improvisation? That's what we'll try to accomplish with our third and final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the Bidirectional LSTM\n",
    "We've seen that making some minor adjustments to the way we define our model's architecture can have a pretty significant impact on test performance. To recap, we changed our `simpleRNN` layer to a `Bidirectional LSTM` layer, and, in line with _Y Benigo's_ research paper, we found that to be an overall improvement in accuracy on test set evaluation. Now, there's a few other parameters in this model that we can fine-tune for better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Adding layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the first optimisation–changing our model architecture. Assume that we have an ideal configuration in mind. That is to say, we can expect great results by doing the following:\n",
    "*   Adding an additional `Bidirectional LSTM` layer\n",
    "*   Adding `Dropout` layers between our `Bidirectional LSTM` and `Dense` layers.\n",
    "*   Adding a `Dense` layer with the `relu` activation function\n",
    "If you want an explanation as to why the above layers improve our word embedding model performance, there's a short lecture from DeepLearning.AI's Natural Language Processing with Sequence Models course covering the use of `Dense` and `ReLu` layers [here](https://www.coursera.org/lecture/sequence-models-in-nlp/dense-and-relu-layers-AGDYm?utm_source=link&utm_medium=page_share&utm_content=vlp&utm_campaign=top_button)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_1. Create a LSTM network and train a model with the train set. As layers, you will use `Embedding`, `Bidirectional LSTM`, `Dropout` and `Dense`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 100)          40259700  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 150, 200)          160800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 150, 200)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 150, 200)          240800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 150, 200)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 150, 512)          102912    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 150, 512)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150, 10)           5130      \n",
      "=================================================================\n",
      "Total params: 40,769,342\n",
      "Trainable params: 40,769,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Embedding(len(vocabulary_words) + 2,\n",
    "                           EMBEDDING_DIM,\n",
    "                           mask_zero=True,\n",
    "                           input_length=MAX_SEQUENCE_LEN))\n",
    "model3.add(Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True)))\n",
    "model3.add(Dropout(0.05))\n",
    "model3.add(Bidirectional(LSTM(EMBEDDING_DIM, return_sequences=True)))\n",
    "model3.add(Dropout(0.05))\n",
    "model3.add(Dense(512, activation = 'relu'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(units=NB_CLASSES+2, activation='softmax'))\n",
    "\n",
    "model3.layers[0].set_weights([embedding_matrix])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2. Compile and fit your network. You will report the training and validation losses and accuracies and comment on the possible overfit._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 390s 3s/step - loss: 0.0614 - acc: 0.8150 - val_loss: 0.0202 - val_acc: 0.9415\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 315s 3s/step - loss: 0.0154 - acc: 0.9478 - val_loss: 0.0151 - val_acc: 0.9547\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 258s 2s/step - loss: 0.0099 - acc: 0.9658 - val_loss: 0.0138 - val_acc: 0.9582\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 225s 2s/step - loss: 0.0075 - acc: 0.9742 - val_loss: 0.0088 - val_acc: 0.9735\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 203s 2s/step - loss: 0.0055 - acc: 0.9806 - val_loss: 0.0091 - val_acc: 0.9721\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 199s 2s/step - loss: 0.0046 - acc: 0.9841 - val_loss: 0.0086 - val_acc: 0.9753\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 286s 2s/step - loss: 0.0036 - acc: 0.9870 - val_loss: 0.0101 - val_acc: 0.9757\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 212s 2s/step - loss: 0.0029 - acc: 0.9897 - val_loss: 0.0094 - val_acc: 0.9725\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 216s 2s/step - loss: 0.0021 - acc: 0.9927 - val_loss: 0.0104 - val_acc: 0.9775\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 236s 2s/step - loss: 0.0017 - acc: 0.9941 - val_loss: 0.0102 - val_acc: 0.9780\n"
     ]
    }
   ],
   "source": [
    "trained = False\n",
    "if trained == False:\n",
    "    history = model3.fit(X, Y_train_cat, \n",
    "                         epochs=EPOCHS, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         validation_data=(X_dev_padded, Y_dev_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3. Apply your network to the test set and report the accuracy you obtained. You will use the `evaluate` method._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 13s 116ms/step - loss: 0.0146 - acc: 0.9655\n",
      "Test loss: 0.014625404961407185\n",
      "Test accuracy: 0.9654780626296997\n"
     ]
    }
   ],
   "source": [
    "# Evaluates with the padding symbol\n",
    "test_loss, test_acc = model3.evaluate(X_test_padded, Y_test_cat)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating your System\n",
    "_1. Use the predict method to predict the tags of the whole test set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test_padded)\n",
    "y_preds = np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove padding\n",
    "Y_test_ = [y[y != 0.] for y in np.argmax(Y_test_cat, axis = 2)]\n",
    "Y_pred_ = [y_hat[y != 0.] for y, y_hat in zip(np.argmax(Y_test_cat, axis = 2), y_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [9 9 5 9 9 9 9 5 9 9 9 9]\n",
      "Actual   : [9 9 5 9 9 9 9 8 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# Compare first predicted sentence tags to actual\n",
    "print(\"Predicted:\", Y_pred_[1])\n",
    "print(\"Actual   :\", Y_test_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2. Write your results in a file, where the two last columns will be the hand-annotated tag and the predicted tag. The fields must be separated by a space and each line must end with a new line: `\\n`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing results to file\n",
    "save(\"output3.txt\", test_dict, ner, Y_test_, Y_pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3. Apply `conlleval` to your output. Report the F1 result._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8290402258292167\n"
     ]
    }
   ],
   "source": [
    "lines = open(\"output3.txt\", encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "improved_score = res['overall']['chunks']['evals']['f1']\n",
    "print(\"F1 score:\", improved_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "if trained == False:\n",
    "    model3.save_weights('model3.model')\n",
    "else:\n",
    "    model3.load_weights('model3.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viola! We were able to successfully improve the resulting F1 score by ~1.9% by adding a few extra layers to our model, namely `Dropout` and `ReLu` layers. In conclusion, we were able to achieve an F1 score of `0.829` on the CoNLL2003 shared task with our final model. While this isn't exactly state-of-the-art (benchmarks [here](https://paperswithcode.com/sota/named-entity-recognition-ner-on-conll-2003?tag_filter=4)), we demonstrated that a few changes to our model could increase performance from 0.72 to 0.82. Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other considerations\n",
    "In case you're still curious, a few more improvements can be made to our LSTM network. While we will leave the training and testing to you, below are some additional considerations you may want to explore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Improving class imbalance\n",
    "The first step we'll take to improve the results of our model is to mitigate the class imbalance. _Class imbalance_ in this case is when one of the target classes has a very high occurence compared to the other classes present. Let's visualise our targets and see where the imbalance is. To do this, we'll use the `numpy.bincount` function which counts the number of occurences of each value in our targets array. In our data, we have 10 classes (8 ner tags + 2 padding symbols)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = NB_CLASSES + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_counts = np.zeros(bins)\n",
    "for y in Y:\n",
    "    target_counts += np.bincount(y, minlength=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.043483e+06, 0.000000e+00, 1.100000e+01, 3.700000e+01,\n",
       "       2.400000e+01, 8.286000e+03, 4.556000e+03, 1.000100e+04,\n",
       "       1.112800e+04, 1.705240e+05])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot distribution of classes\n",
    "plt.bar(x=range(len(target_counts)), height=target_counts);\n",
    "plt.xticks(ticks=range(len(target_counts)), labels= [0,1] + ner);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the bar chart, it's clear that there's a significant skew. This is a problem as most machine learning algorithms assume that the data is evenly distributed within the classes. As a result, our model becomes more biased towards predicting the majority class, $O$. There's significantly less data for the model to learn the patterns of the minority classes (the remaining ner tags).\n",
    "\n",
    "\n",
    "In order to correct for this class imbalance, we can assign different weights to the majority and minority classes. To help us estimate class weights for our unbalanced dataset, we'll use a `sklearn.utils.class_weight` library function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = utils.class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(Y.flatten()), y=Y.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras requires a dict for class_weight\n",
    "class_weight = {i : weights[i] for i in range(9)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By specifying `class_weight='balanced'`, the class weights will be calculated with the formula:\n",
    "```\n",
    "n_samples / (n_classes * np.bincount(y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UPDATE**: `class_weight` not supported for 3+ dimensional targets (see error in `fit()` below). We'll skip this optimisation for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Re-training with further improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to improve our model's F1 score by making a few more adjustments. The previously-trained model weights can be loaded so that we only need to retrain for a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading our trained model\n",
    "trained = True\n",
    "if trained == False:\n",
    "    model3.save_weights('model3.model')\n",
    "else:\n",
    "    model3.load_weights('model3.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Freezing weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy we have is to freeze the `Embedding` layer. If you were paying real close attention to the previous models, you might have noticed that we set this parameter to `True`. We can change this parameter to `False` to avoid updating the already learned weights during our re-training process. The randomly initialised layers in our model trigger a large gradient update during the training process which could interfere with the pre-trained `GloVe` embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing the optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional step in our hyper-parameter tuning is to look at the `optimizer`. To save you some extra time, we will recommend which of the `keras.optimizers` we would go with and why. In [this](https://deepdatascience.wordpress.com/2016/11/18/which-lstm-optimizer-to-use/) comparison of frequently used optimisers, author Bikal Basnet found that the `nadam` optimiser had outperformed our previous optimiser, the `RMSprop`, in LSTM networks. Also, [this](https://ruder.io/optimizing-gradient-descent/index.html) great article by Sebastian Ruder has an animated visualisation of the optimisers on the loss surface as well as a detailed explanation of the `nadam` optimiser and the difference between it and `RMSprop`. We will specify a learning rate for our new optimiser, choosing value `0.001`. Feel free to play around with this hyperparameter and see if you achieve better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=optimizers.Nadam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: `class_weight` not supported for 3+ dimensional targets.\n"
     ]
    }
   ],
   "source": [
    "# Using class_weight\n",
    "try:\n",
    "    re_trained = False\n",
    "    if re_trained == False:\n",
    "        history = model3.fit(X, Y_train_cat, \n",
    "                             epochs=6, \n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             class_weight=class_weight,\n",
    "                             validation_data=(X_dev_padded, Y_dev_cat))\n",
    "    assert False\n",
    "except Exception as e:\n",
    "    print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 206s 2s/step - loss: 0.0010 - acc: 0.9963 - val_loss: 0.0112 - val_acc: 0.9771\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 179s 2s/step - loss: 8.0336e-04 - acc: 0.9971 - val_loss: 0.0126 - val_acc: 0.9777\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 181s 2s/step - loss: 5.9775e-04 - acc: 0.9980 - val_loss: 0.0130 - val_acc: 0.9759\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 179s 2s/step - loss: 5.3505e-04 - acc: 0.9981 - val_loss: 0.0151 - val_acc: 0.9741\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 177s 1s/step - loss: 6.2274e-04 - acc: 0.9976 - val_loss: 0.0149 - val_acc: 0.9762\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 200s 2s/step - loss: 4.2067e-04 - acc: 0.9985 - val_loss: 0.0218 - val_acc: 0.9574\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 180s 2s/step - loss: 0.0019 - acc: 0.9946 - val_loss: 0.0145 - val_acc: 0.9769\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 180s 2s/step - loss: 2.9290e-04 - acc: 0.9989 - val_loss: 0.0158 - val_acc: 0.9771\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 174s 1s/step - loss: 2.4162e-04 - acc: 0.9992 - val_loss: 0.0170 - val_acc: 0.9774\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 177s 2s/step - loss: 2.4307e-04 - acc: 0.9991 - val_loss: 0.0178 - val_acc: 0.9768\n"
     ]
    }
   ],
   "source": [
    "re_trained = False\n",
    "if re_trained == False:\n",
    "    history = model3.fit(X, Y_train_cat, \n",
    "                         epochs=EPOCHS, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         validation_data=(X_dev_padded, Y_dev_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "if re_trained == False:\n",
    "    model3.save_weights('model3_1.model')\n",
    "else:\n",
    "    model3.load_weights('model3_1.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualising the training metrics\n",
    "Now that we've trained our model, we want to visualise the model's training and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'bo', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3. Apply your network to the test set and report the accuracy you obtained. You will use the `evaluate` method._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 21s 178ms/step - loss: 0.0240 - acc: 0.9640\n",
      "Test loss: 0.024024100974202156\n",
      "Test accuracy: 0.9639566540718079\n"
     ]
    }
   ],
   "source": [
    "# Evaluates with the padding symbol\n",
    "test_loss, test_acc = model3.evaluate(X_test_padded, Y_test_cat)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating your System\n",
    "_1. Use the predict method to predict the tags of the whole test set._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model3.predict(X_test_padded)\n",
    "y_preds = np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove padding\n",
    "Y_test_ = [y[y != 0.] for y in np.argmax(Y_test_cat, axis = 2)]\n",
    "Y_pred_ = [y_hat[y != 0.] for y, y_hat in zip(np.argmax(Y_test_cat, axis = 2), y_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [9 9 5 9 9 9 9 5 9 9 9 9]\n",
      "Actual   : [9 9 5 9 9 9 9 8 9 9 9 9]\n"
     ]
    }
   ],
   "source": [
    "# Compare first predicted sentence tags to actual\n",
    "print(\"Predicted:\", Y_pred_[1])\n",
    "print(\"Actual   :\", Y_test_[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_2. Write your results in a file, where the two last columns will be the hand-annotated tag and the predicted tag. The fields must be separated by a space and each line must end with a new line: `\\n`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing results to file\n",
    "save(\"output3_1.txt\", test_dict, ner, Y_test_, Y_pred_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_3. Apply conlleval to your output. Report the F1 result._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8203063457330416\n"
     ]
    }
   ],
   "source": [
    "lines = open(\"output3_1.txt\", encoding='utf8').read().splitlines()\n",
    "res = conlleval.evaluate(lines)\n",
    "improved_score = res['overall']['chunks']['evals']['f1']\n",
    "print(\"F1 score:\", improved_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "This assignment was prepared by _Pierre Nugues_, a phenomenal professor of Semantic Systems and Language Technology at Lunds Tekniska Högskola (bio [here](https://cs.lth.se/pierre/)).\n",
    "\n",
    "Additional credits to [Christopher Marshall](https://medium.com/mysuperai/what-is-named-entity-recognition-ner-and-how-can-i-use-it-2b68cf6f545d) and [Guillamume Genthial](https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html) for making my job of convincing you why NER is worth paying attention to a lot easier. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EDAN95_Lab4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
